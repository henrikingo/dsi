run:
    # Dummy entry to produce a fio-net-listener.ini file, which is used together with fio-net.ini
    # in the following entry.
  - id: fio-net-listener-${mongodb_setup.mongod_config_file.storage.engine}
    type: shell
    cmd: 'echo ">>> fio_net_dummy_entry :      1.0 1"'
    config_filename: fio-net-listener.ini
    workload_config: ${test_control.common_fio_net_config_listener}
  - id: fio-net-${mongodb_setup.mongod_config_file.storage.engine}
    type: shell
    cmd: '${test_control.numactl} ./fio-net-test.sh ${mongodb_setup.meta.hostname}'
    config_filename: fio-net.ini
    workload_config: ${test_control.common_fio_net_config}
  - id: fio-${mongodb_setup.mongod_config_file.storage.engine}.primary_data
    type: shell
    cmd: 'scp -o StrictHostKeyChecking=no fio.ini ${mongodb_setup.meta.hostname}:./; for i in `seq 1 5`; do ssh -A  ${mongodb_setup.meta.hostname} "mkdir -p ./data/fio && ${test_control.numactl} fio  --directory=$(readlink -f ./data) --output-format=json --output=fio.json fio.ini" && scp ${mongodb_setup.meta.hostname}:./fio.json . && python process_fio_results.py -l primary && mv fio.json fio.json.p1.$i; done;  ssh -A  ${mongodb_setup.meta.hostname} "rm -r data/fio"'
    config_filename: fio.ini
    workload_config: |
      [global]
      directory=./data/fio
      filename_format=fiofile.$jobnum.$filenum
      size=1G
      runtime=120
      time_based
      group_reporting
      ioengine=libaio
      direct=1

      [setupfiles]
      stonewall
      filesize=1G
      nrfiles=16
      filename_format=fiofile.$filenum.0
      rw=randrw
      numjobs=1
      runtime=1

      [prequal_check]
      stonewall
      description=This is the test we used for prequal
      rw=randwrite
      bs=16k
      numjobs=16
      norandommap

      [latency_test]
      stonewall
      description=This is for random read and write latency. 1 at a time
      rw=randrw
      numjobs=1
      bs=1
      ioengine=sync
      direct=0
      filesize=1G
      nrfiles=16
      filename_format=fiofile.$filenum.0

      [iops_test]
      stonewall
      description=How many iops can I sustain in parallel
      rw=randrw
      numjobs=32
      bs=4k
      iodepth=32

      [streaming_bandwidth_test]
      stonewall
      description=Measure streaming bandwidth
      rw=rw
      numjobs=16
      bs=16k
      iodepth=32

  - id: benchRun-${mongodb_setup.mongod_config_file.storage.engine}
    type: shell

    # This line to be shortened after the config file is copied from below into the production server.
    cmd: cd workloads &&  ${test_control.numactl} ./run_workloads.py -c workloads.yml
    config_filename: workloads.yml # The name used in previous row
    workload_config:
        ########################################################################
        # Test lists. Command line will indicate which list of tests to execute.
        # The 'default' list is the default.
        # When testing new test workloads, please put your tests in the
        # tests.test list, and remove the existing hello.js
        ########################################################################
        tests:
            default:
              - cpu_noise.js
              - contended_update.js
              - map_reduce.js
              - insert_capped.js
              - insert_ttl.js
              - insert_capped_indexes.js
              - insert_vector.js
              - word_count.js
              - jtrue.js
              - move_chunk.js
              - mongos_read_single.js
              - mongos_insert_vector.js
              - mongos_insert_single.js
              - mongos_50read_50write.js
              - move_chunk_with_load.js
              - index_build.js
            test:
              - # Empty list. Put new workloads here for testing
            short: # Just does Hello World
              - hello.js:
                  parameter1: foo
                  parameter2: [true, false]

        # These next five lines match existing
        # workloads.yml. Workloads needs to be updated to consume from
        # mongo entry.
        target: ${mongodb_setup.meta.hostname}
        port: ${mongodb_setup.meta.port}
        # Hard coding for now. These aren't working right now
        sharded: ${mongodb_setup.meta.is_sharded}
        replica: ${mongodb_setup.meta.is_replset}
        storageEngine: ${mongodb_setup.mongod_config_file.storage.engine}
        test_list: default
        mongo:
            # It turns out the shell supports connection strings, but
            # benchRun itself does not.
            uri: ${mongodb_setup.meta.hosts}
            # Hard coding for now. These aren't working right now
            sharded: ${mongodb_setup.meta.is_sharded}
            replica: ${mongodb_setup.meta.is_replset}
            storageEngine: ${mongodb_setup.mongod_config_file.storage.engine}

pre_task:
  - on_localhost:
      exec: $DSI_PATH/bin/setup-workloads.sh
  - on_workload_client:
      exec: rm -rf workloads*
  - on_workload_client:
      upload_files:
        workloads.tar.gz: workloads.tar.gz
      upload_repo_files:
        bin/process_fio_results.py: process_fio_results.py
        bin/fio-test.sh: fio-test.sh
        bin/fio-net-test.sh: fio-net-test.sh
  - on_workload_client:
      exec: |
        tar zxvf workloads.tar.gz
        chmod 755 fio-test.sh
        chmod 755 fio-net-test.sh
  - on_workload_client:
      upload_files:
        workloads.yml: workloads/workloads.yml
        fio.ini: fio.ini
        fio-net.ini: fio-net.ini
        fio-net-listener.ini: fio-net-listener.ini
post_task:
  - on_workload_client:
      retrieve_files:
        workloads/workload_timestamps.csv: ./reports/workloads_timestamps.csv
        fio.p1.json: ./reports/fio.p1.json
        fio.p2.json: ./reports/fio.p2.json
        fio.p3.json: ./reports/fio.p3.json
        fio.p4.json: ./reports/fio.p4.json
        fio.p5.json: ./reports/fio.p5.json
