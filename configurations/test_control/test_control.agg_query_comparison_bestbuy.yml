run:
  - id: benchRun-${mongodb_setup.mongod_config_file.storage.engine}
    type: shell

    cmd: cd workloads && ${test_control.numactl} ./run_workloads.py -c workloads.yml
    config_filename: workloads.yml  # The name used in previous row
    workload_config:
        ########################################################################
        # Test lists. Command line will indicate which list of tests to execute.
        # The 'default' list is the default.
        # When testing new test workloads, please put your tests in the
        # tests.test list, and remove the existing hello.js
        ########################################################################
        tests:
          default:
            - bestbuy_agg_query_comparison.js:
                - testDbName: bestbuy
                  testCollName: products
                  useAgg: true
                - testDbName: bestbuy
                  testCollName: products
                  useAgg: false
            - cpu_noise.js

        # These next five lines match existing
        # workloads.yml. Workloads needs to be updated to consume from
        # mongo entry.
        target: ${mongodb_setup.meta.hostname}
        port: ${mongodb_setup.meta.port}
        # Hard coding for now. These aren't working right now
        sharded: ${mongodb_setup.meta.is_sharded}
        replica: ${mongodb_setup.meta.is_replset}
        storageEngine: ${mongodb_setup.mongod_config_file.storage.engine}
        test_list: default
  - id: fio-${mongodb_setup.mongod_config_file.storage.engine}
    type: shell
    cmd: '${test_control.numactl} ./fio-test.sh ${mongodb_setup.meta.hostname}'
    config_filename: fio.ini
    workload_config: ${test_control.common_fio_config}
  - id: iperf
    type: shell
    cmd: '${test_control.numactl} ./iperf-test.sh ${mongodb_setup.meta.hostname}'


pre_task:
  - on_localhost:
      exec: $DSI_PATH/bin/setup-workloads.sh
  - on_workload_client:
      exec: rm -rf workloads*
  - on_workload_client:
      # no order is guaranteed between the two upload files. That is okay here
      upload_files:
        workloads.tar.gz: workloads.tar.gz
      upload_repo_files:
        bin/process_fio_results.py: process_fio_results.py
        bin/process_iperf_results.py: process_iperf_results.py
        bin/fio-test.sh: fio-test.sh
        bin/iperf-test.sh: iperf-test.sh
  - on_workload_client:
      # Preshard the cluster if running on a sharded cluster
      exec_mongo_shell:
        connection_string: "${mongodb_setup.meta.hostname}:${mongodb_setup.meta.port}"
        script: |
          if ("${mongodb_setup.meta.is_sharded}" == "True") {

            // Shard the bestbuy.products collection, pre-split it, and disable the balancer.
            assert.commandWorked(sh.enableSharding("bestbuy"));
            assert.commandWorked(
              sh.shardCollection("bestbuy.products",  { "type" : 1, "productId" : 1 }));

            // Disable the balancer. We will explicitly move chunks.
            assert.commandWorked(sh.setBalancerState(false));

            // Presplit the cluster. These split points were some that the system made when allowed to auto split
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "BlackTie", "productId" : NumberLong("1218228664503")}}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "HardGood", "productId" : NumberLong("1218261017938")}}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 105368 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 211661 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 1483577 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 172700 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 197286 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 265900 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 1350924 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 1762474 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Movie", "productId" : 54571 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 91918 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "HardGood", "productId" : NumberLong("1219058138601")}}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Movie", "productId" : 45690 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 68660 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 81225 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 1850075 }}));
            assert.commandWorked(
              db.adminCommand({split: "bestbuy.products", middle: { "type" : "Music", "productId" : 2483269 }}));

            // Move the chunks to specific shards
            db.printShardingStatus();
          } else {
            print ("Non-sharded cluster");
          }
  - on_workload_client:
      exec: |
        rm -rf workloads
        mkdir workloads
        tar zxvf workloads.tar.gz -C workloads
        chmod 755 fio-test.sh
        chmod 755 iperf-test.sh

        # Download and install the dataset
        # Dataset is from the BestBuy Developer API website: https://bestbuyapis.github.io/api-documentation/#overview
        cd data
        curl -O --retry 10 https://s3-us-west-2.amazonaws.com/dsi-donot-remove/AggPerformance/bestbuyproducts.bson.gz
        ~/bin/mongorestore -h ${mongodb_setup.meta.hostname} --port=${mongodb_setup.meta.port} --gzip --archive=bestbuyproducts.bson.gz
  - on_all_hosts:
      # Install iperf. It isn't available in yum on AWS instances
      exec: |
        sudo killall iperf3
        rm -rf iperf
        git clone https://github.com/esnet/iperf
        cd iperf/
        ./configure
        make
        sudo make install
  - on_workload_client:
      upload_files:
        workloads.yml: workloads/workloads.yml
        fio.ini: fio.ini
post_task:
  - on_workload_client:
      retrieve_files:
        workloads/workload_timestamps.csv: ../workloads_timestamps.csv
        fio.json: ../fio.json
        iperf.json: ../iperf.json
      exec: |
        rm data/bestbuy* # Cleanup download files.
      exec_mongo_shell:
        connection_string: "${mongodb_setup.meta.hostname}:${mongodb_setup.meta.port}"
        script: |
          if ("${mongodb_setup.meta.is_sharded}" == "True") {
            // re-enable the balancer
            assert.commandWorked(sh.setBalancerState(true));
            db.printShardingStatus();
          }
