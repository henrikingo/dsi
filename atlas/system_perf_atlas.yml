stepback: false
command_type: system

pre:

post:
    - command: shell.exec
      params:
        working_dir: work
        script: |
          source ./dsienv.sh
          make_artifact.sh
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: work/dsi-artifacts.tgz
        remote_file: ${project}/${build_variant}/${revision}/${task_id}/${version_id}/logs/dsi-artifacts-${task_name}-${build_id}-${execution}.${ext|tgz}
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: Dsi Artifacts - Execution ${execution}
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/workloads/workloads/jsdoc/jsdocs-redirect.html
        remote_file: ${project}/${build_variant}/${revision}/${task_id}/${version_id}/logs/workloads-${task_name}-${build_id}.html
        bucket: mciuploads
        permissions: public-read
        content_type: text/html
        display_name: workloads documentation
    - command: attach.results
      params:
        file_location: work/report.json
    - command: "json.send"
      params:
         name: "perf"
         file: "work/perf.json"
    - command: shell.exec
      params:
        working_dir: work
        script: |
          source ./dsienv.sh
          ../src/run-dsi infrastructure_teardown.py

functions:
  "prepare environment":
    - command: shell.exec
      params:
        script: |
          rm -rf ./*
          mkdir src
          mkdir work
    - command: manifest.load
    - command: git.get_project
      params:
        directory: src
        revisions: # for each module include revision as <module_name> : ${<module_name>_rev}
          workloads: ${workloads_rev}
          genny: ${genny_rev}
          linkbench: ${linkbench_rev}
    - command: shell.exec
      params:
        working_dir: work
        script: |
          cat > bootstrap.yml <<EOF
          infrastructure_provisioning: workload_client
          platform: linux
          mongodb_setup: atlas
          atlas_setup: ${atlas_setup}
          test_control: ${test}
          production: true
          workloads_dir: ../src/workloads/workloads
          ycsb_dir: ../src/YCSB/YCSB
          genny_dir: ../src/genny/genny
          linkbench_dir: ../src/linkbench/linkbench
          EOF

          cat > runtime.yml <<EOF
          # evergreen default expansions
          branch_name: ${branch_name}
          build_id: ${build_id}
          build_variant: ${build_variant}
          execution: ${execution}
          is_patch: ${is_patch|false}
          order: ${revision_order_id}
          project: ${project}
          project_dir: ${project_dir}
          revision: ${revision}
          task_id: ${task_id}
          task_name: ${task_name}
          version_id: ${version_id}
          workdir: ${workdir}

          # sys-perf expansions
          # Shouldn't be needed: testList: ${testList}
          ext: ${ext}
          script_flags : ${script_flags}
          dsi_rev: ${dsi_rev}
          workloads_rev: ${workloads_rev}
          linkbench_rev: ${linkbench_rev}
          EOF

    - command: shell.exec
      params:
        silent: true
        working_dir: work
        script: |
          # AWS ssh secret key
          echo "${ec2_pem}" > aws_ssh_key.pem
          chmod 400 aws_ssh_key.pem

          cat > runtime_secret.yml <<EOF
          # Note that inside system_perf.yml we have ${aws_key} & ${aws_secret}, which are used for
          # Evergreen resources. The below are used for dsi resources, and are NOT the same!
          aws_access_key: "${terraform_key}"
          aws_secret_key: "${terraform_secret}"
          perf_jira_user: "${perf_jira_user}"
          perf_jira_pw: "${perf_jira_pw}"
          dsi_analysis_atlas_user: "${dsi_analysis_atlas_user}"
          dsi_analysis_atlas_pw: "${dsi_analysis_atlas_pw}"
          atlas_api_user: "${atlas_api_user}"
          atlas_api_key: "${atlas_api_key}"
          atlas_database_user: "${atlas_database_user}"
          atlas_database_password: "${atlas_database_password}"
          EOF
          chmod 400 runtime_secret.yml
    - command: expansions.write
      params:
        file: work/expansions.yml
    - command: shell.exec
      params:
        working_dir: work
        script: |
          set -e
          ../src/run-dsi python ../src/bin/bootstrap.py
    # Different work directory due to historical reasons
    - command: shell.exec
      params:
        script: |
          set -v
          set -e
          source work/dsienv.sh
          setup-dsi-env.sh
          ls -a work

  "deploy cluster":
    - command: shell.exec
      params:
        working_dir: work
        script: |
          set -e
          set -v
          source ./dsienv.sh
          ../src/run-dsi infrastructure_provisioning.py
          ../src/run-dsi workload_setup.py
          ../src/run-dsi mongodb_setup.py

  "run test":
    - command: shell.exec
      type: test
      params:
        working_dir: work
        script: |
          set -e
          set -v
          source ./dsienv.sh
          ../src/run-dsi test_control.py
    - command: "json.send"
      params:
         name: "perf"
         file: "work/perf.json"

  "analyze":
    - command: shell.exec
      params:
        working_dir: work
        script: |
          ../src/run-dsi detect-changes
    - command: shell.exec
      type : test
      params:
        working_dir: work
        script: |
          set -o errexit
          set -o verbose
          TAG="4.0.2-Baseline"
          OVERRIDEFILE="../src/analysis/${branch_name}/system_perf_override.json"
          python -u ../src/analysis/post_run_check.py ${script_flags} --reports-analysis reports --perf-file perf.json --rev ${revision} --refTag $TAG --overrideFile $OVERRIDEFILE --project_id sys-perf --variant ${build_variant} --task ${task_name}

#######################################
#               Tasks                 #
#######################################

tasks:
- name: linkbench
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "linkbench"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: tpcc
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "tpcc"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: insert_remove
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "insert_remove"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: service_architecture_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "service_architecture_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: big_update
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "big_update"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: industry_benchmarks
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "ycsb"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: industry_benchmarks_secondary_reads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "ycsb-secondary-reads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: industry_benchmarks_wmajority
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "ycsb-wmajority"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: crud_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "crud_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: mixed_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "mixed_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: misc_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "misc_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: map_reduce_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "map_reduce_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: smoke_test
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "short"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: retryable_writes_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "retryable_writes"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: snapshot_reads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "snapshot_reads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: secondary_reads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "secondary_reads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: bestbuy_agg
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "bestbuy_agg"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: bestbuy_query
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "bestbuy_query"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: non_sharded_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "non_sharded"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: mongos_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "mongos"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: move_chunk_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "move_chunk"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: move_chunk_waiting_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "move_chunk_waiting"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: secondary_performance
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        # Unfortunately the dash/underscore style is different for mongodb_setup and test_control
        test: "secondary_performance"
        setup: "secondary-performance"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: initialsync
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "initialsync"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: initialsync-logkeeper
  priority: 5
  exec_timeout_secs: 216000 # 2.5 days
  commands:
    - func: "prepare environment"
      vars:
        test: "initialsync-logkeeper"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: change_streams_throughput
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "change_streams_throughput"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: change_streams_latency
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "change_streams_latency"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: change_streams_multi_mongos
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "change_streams_multi_mongos"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

#######################################
#               Modules               #
#######################################
# if a module is added and to be added to the manifest
# be sure to add the module to git.get_project revisions parameter
modules:
- name: workloads
  repo: git@github.com:10gen/workloads.git
  prefix: workloads
  branch: master

- name: genny
  repo: git@github.com:mongodb/genny.git
  prefix: genny
  branch: master

- name: linkbench
  repo: git@github.com:10gen/linkbench.git
  prefix: linkbench
  branch: master

#######################################
#         Buildvariants               #
#######################################

buildvariant_templates:  # Dummy key that evergreen ignores
- &buildvariant_template
  name: variant-name-here
  display_name: Variant Name Here
  # 10 years. The intent is to only schedule Atlas tests manually when needed.
  batchtime: 5256000
  modules: &modules
    - genny
    - workloads
    - linkbench
  expansions:
    atlas_setup: lookup-key
  run_on:
      - "rhel70-perf-atlas"
  tasks: &3nodetasks
    - name: industry_benchmarks
    - name: industry_benchmarks_secondary_reads
#    - name: crud_workloads
#    - name: mixed_workloads
#    - name: misc_workloads
#    - name: map_reduce_workloads
#    - name: smoke_test
#    - name: retryable_writes_workloads
    - name: industry_benchmarks_wmajority
#    - name: secondary_performance
#    - name: non_sharded_workloads
#    - name: bestbuy_agg
#    - name: bestbuy_query
#    - name: change_streams_throughput
#    - name: change_streams_latency
#    - name: snapshot_reads
#    - name: secondary_reads
    - name: linkbench
    - name: insert_remove
    - name: big_update
    - name: tpcc
    - name: service_architecture_workloads



buildvariants:
- <<: *buildvariant_template
  name: M10-atlas-repl
  display_name: M10 Atlas ReplSet
  expansions:
    atlas_setup: M10-repl

- <<: *buildvariant_template
  name: M20-atlas-repl
  display_name: M20 Atlas ReplSet
  expansions:
    atlas_setup: M20-repl

- <<: *buildvariant_template
  name: M30-atlas-repl
  display_name: M30 Atlas ReplSet
  expansions:
    atlas_setup: M30-repl

- <<: *buildvariant_template
  name: M40-atlas-repl
  display_name: M40 Atlas ReplSet
  expansions:
    atlas_setup: M40-repl

- <<: *buildvariant_template
  name: M50-atlas-repl
  display_name: M50 Atlas ReplSet
  expansions:
    atlas_setup: M50-repl

- <<: *buildvariant_template
  name: M60-atlas-repl
  display_name: M60 Atlas ReplSet
  expansions:
    atlas_setup: M60-repl

- <<: *buildvariant_template
  name: M100-atlas-repl
  display_name: M100 Atlas ReplSet
  expansions:
    atlas_setup: M100-repl

# - <<: *buildvariant_template
#   name: M140-atlas-repl
#   display_name: M140 Atlas ReplSet
#   expansions:
#     atlas_setup: M140-repl

- <<: *buildvariant_template
  name: M200-atlas-repl
  display_name: M200 Atlas ReplSet
  expansions:
    atlas_setup: M200-repl

- <<: *buildvariant_template
  name: M300-atlas-repl
  display_name: M300 Atlas ReplSet
  expansions:
    atlas_setup: M300-repl

# Note: This is not obvious in the UI, but if you look closely you see that M400 doesn't exist
# at all in the "General" variation, rather only the M400_NVMe and R400 exist.


- <<: *buildvariant_template
  name: R40-atlas-repl
  display_name: R40 Atlas ReplSet
  expansions:
    atlas_setup: R40-repl

- <<: *buildvariant_template
  name: R50-atlas-repl
  display_name: R50 Atlas ReplSet
  expansions:
    atlas_setup: R50-repl

- <<: *buildvariant_template
  name: R60-atlas-repl
  display_name: R60 Atlas ReplSet
  expansions:
    atlas_setup: R60-repl

- <<: *buildvariant_template
  name: R80-atlas-repl
  display_name: R80 Atlas ReplSet
  expansions:
    atlas_setup: R80-repl

- <<: *buildvariant_template
  name: R200-atlas-repl
  display_name: R200 Atlas ReplSet
  expansions:
    atlas_setup: R200-repl

# - <<: *buildvariant_template
#   name: R300-atlas-repl
#   display_name: R300 Atlas ReplSet
#   expansions:
#     atlas_setup: R300-repl

- <<: *buildvariant_template
  name: R400-atlas-repl
  display_name: R400 Atlas ReplSet
  expansions:
    atlas_setup: R400-repl

# - <<: *buildvariant_template
#   name: R700-atlas-repl
#   display_name: R700 Atlas ReplSet
#   expansions:
#     atlas_setup: R700-repl

- <<: *buildvariant_template
  name: M40-nvme-atlas-repl
  display_name: M40 Atlas NVME ReplSet
  expansions:
    atlas_setup: M40_NVME-repl

- <<: *buildvariant_template
  name: M50-nvme-atlas-repl
  display_name: M50 NVMe Atlas ReplSet
  expansions:
    atlas_setup: M50_NVME-repl

- <<: *buildvariant_template
  name: M60-atlas-NVME-repl
  display_name: M60 NVMe Atlas ReplSet
  expansions:
    atlas_setup: M60_NVME-repl

- <<: *buildvariant_template
  name: M80-atlas-NVME-repl
  display_name: M80 NVMe Atlas ReplSet
  expansions:
    atlas_setup: M80_NVME-repl

- <<: *buildvariant_template
  name: M200-atlas-NVME-repl
  display_name: M200 NVMe Atlas ReplSet
  expansions:
    atlas_setup: M200_NVME-repl

# US_EAST_1 only (which is exactly what we use)
- <<: *buildvariant_template
  name: M400-atlas-NVME-repl
  display_name: M400 NVMe Atlas ReplSet
  expansions:
    atlas_setup: M400_NVME-repl
