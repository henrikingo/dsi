"""Functions for analyzing the throughput-over-time data generated by YCSB."""

import logging
import os
import itertools
import collections
import math

import structlog

LOGGER = structlog.get_logger(__name__)

Throughput = collections.namedtuple("Throughput", ["time", "ops"])


def ycsb_throughput(config, results):
    """
    analysis.py plugin: Check YCSB throughput over time

    Note: Even if this runs every time and scans all directories in reports/, it will be a no-op
    for non-YCSB tests when it doesn't find the YCSB stdout output it looks for.

    :param ConfigDict config: The global config.
    :param ResultsFile results: Object to add results to.
    """
    LOGGER.info("Checking YCSB throughput.")
    path = config['test_control']['reports_dir_basename']
    results.extend(analyze_ycsb_throughput(path))


def analyze_ycsb_throughput(reports_dir_path):
    """
    Search `reports_dir_path` for YCSB log files (any file whose name starts with
    "test_screen_capture"), extract their throughput-over-time data, and analyze it for errors like
    periods of significantly decreased throughput. Return a list of test-result dictionaries that
    can be plugged straight into a "report.json" file.
    """

    results = []
    for num, path in enumerate(_get_ycsb_file_paths(reports_dir_path)):
        LOGGER.info("Reading file:", path=path)
        # Check that this is a ycsb output file
        ycsb_in_file = True
        with open(path) as ycsb_file:
            if max((line.find('YCSB Client') for line in ycsb_file)) == -1:
                ycsb_in_file = False
                LOGGER.warning('YCSB Throughput analysis called on file without YCSB Call for file',
                               path=path)
        if ycsb_in_file:
            with open(path) as ycsb_file:
                throughputs = _throughputs_from_lines(ycsb_file)

            if isinstance(throughputs, list) and len(throughputs) >= 2:
                pass_test, result_message = _analyze_throughputs(throughputs)
            else:
                pass_test = False
                result_message = "No throughput data found in: {0}".format(path)
                LOGGER.error(result_message)

            results.append({
                "status": "pass" if pass_test else "fail",
                "log_raw": "File: {0}\n".format(path) + result_message,
                "test_file": "ycsb-throughput-analysis." + str(num),
                "start": 0,
                "exit_code": 0 if pass_test else 1
            })

    return results


def _get_ycsb_file_paths(directory_path):
    """
    Recursively search the directory tree starting at `directory_path` for files whose name starts
    with "test_screen_capture.log" and return a list of their fully qualified paths.
    """

    file_paths = []
    for sub_directory_path, _, filenames in os.walk(directory_path):
        for filename in filenames:
            if filename.startswith("test_output.log"):
                file_paths.append(os.path.join(sub_directory_path, filename))

    return file_paths


def _throughputs_from_lines(lines):
    """
    Search `lines`, a list of the lines taken from a YCSB log file, for throughput data, and return
    it in the form of a list of `(time, throughput)` tuples, where `throughput` is the ops/sec
    throughput value and `time` is the number of seconds since the start of the test that the
    throughput value was reported at.
    """

    # A sample line from the YCSB file might look like:
    # " 10 sec: 185680 operations; 18543.89 current ops/sec; [INSERT AverageLatency(us)=1692.38]"

    throughputs = []
    for line in lines:
        if not line.startswith(" "):
            continue

        line = line.strip()
        components = line.split(": ", 1)
        if len(components) < 2:
            continue

        timestamp_str, rest = components
        timestamp = float(timestamp_str.split(" ")[0])

        components = rest.split("; ")
        if len(components) < 2:
            continue

        ops_per_sec = float(components[1].split(" ")[0])
        throughputs.append(Throughput(timestamp, ops_per_sec))

    return throughputs


def _analyze_throughputs(throughputs):
    """
    Analyze `throughputs`, a list of `Throughput`s, for anomalous performance using the
    `_analyze_*()` functions. Return `(passed, message)`, where `passed` is a boolean indicating
    whether the analysis passed successfully (ie no problems were detected) and `message` is a
    human-friendly message summarizing the analysis results.
    """

    err_messages = _analyze_spiky_throughput(throughputs)
    err_messages += _analyze_long_term_degradation(throughputs)
    passed = not err_messages
    return passed, "No problems detected." if passed else "\n".join(err_messages)


def _analyze_spiky_throughput(throughputs, max_drop=0.5, min_duration=10, skip_initial_seconds=10):  # pylint: disable=too-many-locals
    """
    Analyze throughput data for periods of reduced throughput. Any throughput value that is less
    than the average throughput of the entire run multiplied by `max_drop` is considered a "low"
    throughput; any period of successive low throughputs that's greather than or equal to
    `min_duration` (a number of seconds) is considered an error. Note that we may want to ignore the
    first few datapoints because the test is "warming up" and needs a little bit of time before
    hitting its initial maximum throughput; the amount of time to skip at the beginning of the test
    is specified in `skip_initial_seconds` in seconds (so if `skip_initial_seconds=20` the first 20
    seconds worth of datapoints will be skipped). The function returns a list of detailed error
    messages (`strings`), which is empty if no problems were detected in the throughput data.
    """

    err_messages = []

    # Skip datapoints based on `skip_initial_seconds`. `throughputs` is a list of `(time,
    # throughput)` tuples.
    while throughputs and throughputs[0].time <= skip_initial_seconds:
        throughputs = throughputs[1:]

    if not throughputs:
        return True, (
            "Insufficient data to perform throughput analysis (less than {0} seconds of data "
            "was present).")

    avg_throughput = float(sum(pair.ops for pair in throughputs)) / len(throughputs)
    min_acceptable_throughput = avg_throughput * max_drop
    throughputs_iter = iter(throughputs)

    for throughput in throughputs_iter:
        if throughput.ops < min_acceptable_throughput:
            first_low_throughput_time = throughput.time

            # Search until the point where performance numbers return to normal.
            low_throughputs = list(
                itertools.takewhile(lambda throughput: throughput.ops < min_acceptable_throughput,
                                    throughputs_iter))

            # If there aren't at least two consecutive low throughputs there aren't enough
            # datapoints to confidently flag a regression, no matter what the reporting interval is.
            if not low_throughputs:
                continue

            last_low_throughput_time = low_throughputs[-1].time
            duration = last_low_throughput_time - first_low_throughput_time
            if duration >= min_duration:
                # We've detected a long-enough period of reduced throughput.

                low_throughputs_str = "\n".join("    {0} sec: {1} ops/sec".format(time, throughput)
                                                for time, throughput in low_throughputs)
                err_msg = (
                    "spiky throughput: Detected low throughput for {0} seconds, starting at {1} "
                    "seconds and ending at {2} seconds. The minimum acceptable throughput is {3} "
                    "ops/sec (the average throughput for the test was {4}ops/sec ), and the low "
                    "throughputs were: \n{5}\n").format(duration, first_low_throughput_time,
                                                        last_low_throughput_time,
                                                        min_acceptable_throughput, avg_throughput,
                                                        low_throughputs_str)
                err_messages.append(err_msg)

    return err_messages


def _analyze_long_term_degradation(throughputs, duration_seconds=10 * 60, max_drop=0.7):
    """Analyze `throughputs`, a list of `Throughput`s, for long term
    degradation in throughput. The `throughputs` are looked at in
    `duration_seconds` chunks (so every single sequence of consecutive
    `Throughput`s that take up a chunk of time equal to
    `duration_seconds`), and the average throughput of each chunk is
    computed. If the average throughput is less than the maximum
    throughput of the entire run multiplied by `max_drop`, it's
    flagged as a long-term degradation.  The maximum throughput is
    computed with the same length of time as the sliding windows. The
    function returns a list of detailed `string` error messages, which

    is empty if no problems were detected in the throughput data.

    The differences between `_analyze_long_term_degradation()` and `_analyze_spiky_throughput()` are
    that: `_analyze_long_term_degradation()` uses the maximum throughput of the run, and not the
    average throughput, as its comparison point. Also, for each chunk that it compares against the
    maximum throughput, it uses the chunk's average throughput instead of comparing every single
    throughput datapoint inside it.

    """

    err_messages = []

    reporting_interval = throughputs[1].time - throughputs[0].time
    data_window_width = int(math.ceil(float(duration_seconds) / reporting_interval))

    # Only do the calculation if there is enough data.
    if len(throughputs) > data_window_width:
        # This computes the max throughput over any data_window_width period of time
        max_throughput = max(
            average_throughput(throughputs[x:x + data_window_width])
            for x in range(len(throughputs) - data_window_width))
        min_acceptable_throughput = max_throughput * max_drop
        failures = [
            x for x in range(len(throughputs) - data_window_width)
            if average_throughput(throughputs[x:x + data_window_width]) < min_acceptable_throughput
        ]
        for failure in failures:
            avg_throughput = average_throughput(throughputs[failure:failure + data_window_width])
            start_time = throughputs[failure].time
            end_time = throughputs[failure + data_window_width].time
            err_message = (
                "long term throughput degradation: Detected a low average throughput of {0} "
                "starting at {1} and ending at {2} (total duration of {3} seconds). The maximum "
                "throughput of the run was {4}, so the minimum acceptable throughput was "
                "{5}.\n").format(avg_throughput, start_time, end_time, end_time - start_time,
                                 max_throughput, min_acceptable_throughput)
            err_messages.append(err_message)

    return err_messages


def average_throughput(throughputs):
    """Return the average `ops` value of `throughputs`, a list of `Throughput`s."""

    return float(sum(throughput.ops for throughput in throughputs)) / len(throughputs)
