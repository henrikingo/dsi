# String that will be used in the path of the installation directory.
# Useful to test multiple versions of MongoDB on same infrastructure (manual runs for analysing
# build failures).
# Note: mongo_root is the directory where a mongodb.tar.gz was extracted.
# <mongo_root>/bin has the binaries.
mongo_dir: mongodb
# Note: It's also allowed to upload your own binary. You can unset this by setting to the empty
# string "".
mongodb_binary_archive: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-amazon-3.4.6.tgz

journal_dir: /media/ephemeral1/journal  # If specified, create a symlink to have journal at this path
clean_db_dir: true

mongod_config_file:  # This section is literally a mongod config file
  replication:  # As specified in https://docs.mongodb.org/manual/reference/configuration-options/
    replSetName: myrs0  # We will use this and completely cease using command line options
  storage:  # A test can specify any option supported by mongod, including undocumented ones
    engine: wiredTiger
  net:
    port: 27017
    bindIp: 0.0.0.0

authentication:
  enabled: true
  username: username
  password: password

# etc...
rs_conf:  # The top level settings for rs.conf() / rs.initiate()
  protocolVersion: 1  # See also node specific settings under topology
  settings:
    heartbeatTimeoutSecs: 10

mongos_config_file: ...
configsvr_config_file: ...

# Ordered list of steps to take before starting the mongo processes. Each item is guaranteed to
# complete before the next one.
#
# Keys in the list can be on_all_hosts, on_workload_client, on_mongod, on_mongos, on_configsvr,
# on_host, on_servers.
pre_cluster_start:
  - on_all_hosts:
      download_files:
        - source: http://url1
          target: remote_file_path1
        - source: http://url2
          target: remote_file_path2
  - on_all_hosts:
      upload_files:
        - source: local_path/file1
          target: remote_path/file1
  - on_all_hosts:
      exec: |
  # This would execute in OS shell (before MongoDB cluster is running)
  - on_workload_client:
      exec_mongo_shell:
        script: |
        # JavaScript to be executed in a mongo shell (when MongoDB cluster is running)
        connection_string: ${mongodb_setup.meta.hosts}  # Defaults to localhost
  - on_servers: (see above)  # servers = union( mongod, mongos, configsvr) = all_hosts - workload_client
  - on_mongod: (see above)
  - on_mongos: (see above)
  - on_configsvr: (see above)
  - on_host: (see system_setup.yml)

# Ordered list of steps to after starting the mongo processes
post_cluster_start:
  - on_all_hosts:
      exec: |
# This would execute in OS shell (after MongoDB cluster is running)

# These are the same as in test_control.yml. Use them here for mongodb related pre and post tasks.
pre_task: (See example below)
post_task:
  - on_mongod:
      retrieve_files:
        - source: data/logs/mongod.log
          target: ./mongod.log
        - source: data/dbs/diagnostic.data
          target: ./diagnostic.data
  - on_mongos:
      retrieve_files:
        - source: data/logs/mongos.log
          target: ./mongos.log
  - on_configsvr:
      retrieve_files:
        - source: data/logs/mongod.log
          target: ./mongod.log
        - source: data/dbs/diagnostic.data
          target: ./diagnostic.data
  # For Atlas clusters, the above do nothing, but the below does the same over REST.
  - on_atlas:
      # The value is actually ignored, but there needs to be a non-empty value.
      retrieve_logs: true


# This defines the cluster topology to deploy, and what to deploy on which IP address.
# Note: it is also possible to override mongod/mongos config file entries on a per-node basis.
topology:
  # Note: It is allowed to, even if most tests wouldn't, specify multiple sharded clusters, replica
  # sets and/or standalone mongod's. Hence a list is used.
  # Initial sync test would specify one 2-node replica set, and a separate standalone server.
  - id: mycluster  # Optional. Needed if someone ever would configure more than 1 cluster.
    cluster_type: sharded_cluster
    configsvr:
      - public_ip: ${infrastructure_provisioning.out.configsvr.0.public_ip}
        private_ip: ${infrastructure_provisioning.out.configsvr.0.private_ip}
        config_file: ...  # See the last mongod's below for an example of node specific config
      - public_ip: ${infrastructure_provisioning.out.configsvr.1.public_ip}
        private_ip: ${infrastructure_provisioning.out.configsvr.1.private_ip}
      - public_ip: ${infrastructure_provisioning.out.configsvr.2.public_ip}
        private_ip: ${infrastructure_provisioning.out.configsvr.2.private_ip}
    mongos:
      - public_ip: ${infrastructure_provisioning.out.mongos.0.public_ip}
        private_ip: ${infrastructure_provisioning.out.mongos.0.private_ip}
        config_file: ...  # See the last mongod's below for an example of node specific config
      - public_ip: ${infrastructure_provisioning.out.mongos.1.public_ip}
        private_ip: ${infrastructure_provisioning.out.mongos.1.private_ip}
      - public_ip: ${infrastructure_provisioning.out.mongos.2.public_ip}
        private_ip: ${infrastructure_provisioning.out.mongos.2.private_ip}
    shard:
      - id: myrs0
        # If specified, used as shard name when deploying the cluster.
        # Note: replset name = config_file.replication.replSetName.
        cluster_type: replset
        mongod:
          - public_ip: ${infrastructure_provisioning.out.mongod.0.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.0.private_ip}
            id: my_unique_id  # Shards, replica sets and mongod/mongos processes can have a unique id
          - public_ip: ${infrastructure_provisioning.out.mongod.1.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.1.private_ip}
          - public_ip: ${infrastructure_provisioning.out.mongod.2.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.2.private_ip}
      - id: myrs1
        cluster_type: replset
        rs_conf:  # It is possible to set top level rs.conf() settings on a per shard basis here
          protocolVersion: 0
        mongod:
          - public_ip: ${infrastructure_provisioning.out.mongod.3.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.3.private_ip}
            rs_conf_member:  # The member specific part of rs.conf() json object, to go under rs.conf().member[0]
              priority: 2
          - public_ip: ${infrastructure_provisioning.out.mongod.4.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.4.private_ip}
          - public_ip: ${infrastructure_provisioning.out.mongod.5.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.5.private_ip}
      - id: myrs2
        cluster_type: replset
        mongod:
          # Testing a cluster where some nodes are of a different version.
          # This references mongodb_binary_archive from above, version 3.4.6.
          - mongodb_binary_archive: ${mongodb_setup.mongodb_binary_archive}
            config_file: &diff_mongod_config  # And a different config
              storage:  # Note: These are merged (or "upserted") into the global/common mongod_config_file specified above
                engine: inMemory
            public_ip: ${infrastructure_provisioning.out.mongod.6.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.6.private_ip}
          # The mongodb binary used for this node is the version listed below
          - mongodb_binary_archive: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-amazon-3.4.7.tgz
            config_file: *diff_mongod_config
            public_ip: ${infrastructure_provisioning.out.mongod.7.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.7.private_ip}
          # The mongodb binary used for this node is the version listed below
          - mongodb_binary_archive: https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-amazon-3.4.7.tgz
            config_file: *diff_mongod_config
            public_ip: ${infrastructure_provisioning.out.mongod.7.public_ip}
            private_ip: ${infrastructure_provisioning.out.mongod.7.private_ip}
  # Note: For replica sets (including shards with more than a single node), the default priorities
  # are 2 for the first node and 1 for the rest
  - cluster_type: replset
    mongod:
      - id: myreplica1
        public_ip: ${infrastructure_provisioning.out.mongod.0.public_ip}
        private_ip: ${infrastructure_provisioning.out.mongod.0.private_ip}
      - id: myreplica2
        public_ip: ${infrastructure_provisioning.out.mongod.1.public_ip}
        private_ip: ${infrastructure_provisioning.out.mongod.1.private_ip}
      - id: myreplica3
        public_ip: ${infrastructure_provisioning.out.mongod.2.public_ip}
        private_ip: ${infrastructure_provisioning.out.mongod.2.private_ip}
  - cluster_type: standalone
    id: mynode1
    public_ip: ${infrastructure_provisioning.out.mongod.0.public_ip}
    private_ip: ${infrastructure_provisioning.out.mongod.0.private_ip}


# Meta data about this mongodb setup.
# It is possible to provide meta data that is not used by mongodb_setup itself, but that can be
# convenient to reference from the other modules. In particular, see the test_control module doing
# that in run.0.workload_config.mongo
meta:
  # The list of hosts that can be used in a mongodb connection string
  hosts: ${mongodb_setup.topology.0.mongos.0.private_ip}:27017,${mongodb_setup.topology.0.mongos.1.private_ip}:27017,${mongodb_setup.topology.0.mongos.2.private_ip}:27017
  # A single host, as in "host:port". Use the primary or first mongos.
  hostname: ${mongodb_setup.topology.0.mongos.0.private_ip}
  port: 27017
  is_sharded: true
  is_replset: false
  storageEngine: ${mongodb_setup.mongod_config_file.storage.engine}
  mongodb_setup: standalone
  mongodb_url: mongodb://${mongodb_setup.authentication.username}:${mongodb_setup.authentication.password}@${mongodb_setup.meta.hosts}/admin?ssl=false

# Hosts to run correctness tests on
validate:
  # Standalone hosts will have validate called on them
  standalone:
    - ${mongodb_setup.topology.2.private_ip}:27017
  # Primaries will run validate and dbhash
  primaries:
    - ${mongodb_setup.topology.0.shard.0.mongod.0.private_ip}:27017
    - ${mongodb_setup.topology.0.shard.1.mongod.0.private_ip}:27017
    - ${mongodb_setup.topology.0.shard.2.mongod.0.private_ip}:27017
    - ${mongodb_setup.topology.0.configsvr.0.private_ip}:27017

# These params are passed through to shutdownServer, it allows whatever
# https://docs.mongodb.com/manual/reference/command/shutdown/#dbcmd.shutdown supports.
# The values are defaulted (in defaults.yml) so are not required.
# See https://jira.mongodb.org/browse/SERVER-32679 for why timeoutSecs < 120.
shutdown_options:
  force: true
  timeoutSecs: 119

# These timeouts specify the max amount of milliseconds that the mongo shutdownServer command and
# pkill mongo commands can run for
timeouts:
  shutdown_ms: 540000
  sigterm_ms: 60000

# defaults.yml contains the following but it can be over-ridden
upon_error:
  - on_all_servers:
      exec: |
        df
        du  --si  --max-depth 1 ./data
      retrieve_files:
        - source: data/logs/
          target: ./
  - on_mongod:
      retrieve_files:
        - source: data/dbs/diagnostic.data
          target: ./diagnostic.data
  - on_configsvr:
      retrieve_files:
        - source: data/dbs/diagnostic.data
          target: ./diagnostic.data
